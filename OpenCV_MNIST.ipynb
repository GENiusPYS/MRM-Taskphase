{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c05181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a279db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(7 * 7 * 64, 1000),\n",
    "            nn.Linear(1000, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = torch.flatten(out, 1) \n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8087960d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=3136, out_features=1000, bias=True)\n",
       "    (2): Linear(in_features=1000, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"C:\\\\Users\\\\SWETHA\\\\conv_net_model.ckpt\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37046c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8b7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "canvas = None\n",
    "\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "\n",
    "noise_thresh = 800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bdbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HSV values for pen detection\n",
    "load_from_sys = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f4ce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76,  97,   0],\n",
       "       [179, 255, 255]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if load_from_sys:\n",
    "    hsv_value = np.load('hsv_value.npy')\n",
    "lower_range = hsv_value[0]\n",
    "upper_range = hsv_value[1]\n",
    "hsv_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a12f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    if canvas is None:\n",
    "        canvas = np.zeros_like(frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours and cv2.contourArea(max(contours, key=cv2.contourArea)) > noise_thresh:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        x2, y2, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        if x1 == 0 and y1 == 0:\n",
    "            x1, y1 = x2, y2\n",
    "        else:\n",
    "            canvas = cv2.line(canvas, (x1, y1), (x2, y2), [0, 255, 255], 4)\n",
    "\n",
    "        x1, y1 = x2, y2\n",
    "    else:\n",
    "        x1, y1 = 0, 0\n",
    "\n",
    "    # Preprocess the live writing input image\n",
    "    gray = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY)\n",
    "    resized_gray = cv2.resize(gray, (28, 28))\n",
    "    resized_gray = resized_gray.astype(np.float32) / 255.0  # Normalize the image\n",
    "    tensor_img = torch.tensor(resized_gray).unsqueeze(0).unsqueeze(0).to(device)  # Add batch and channel dimensions\n",
    "\n",
    "    # Use the trained model to predict the digit\n",
    "    with torch.no_grad():\n",
    "        model_output = model(tensor_img)\n",
    "        _, predicted_label = torch.max(model_output, 1)\n",
    "\n",
    "    digit = predicted_label.item()\n",
    "\n",
    "    # Display the predicted digit on the screen\n",
    "    cv2.putText(canvas, f\"Predicted Digit: {digit}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Merge the canvas with the frame for display\n",
    "    frame = cv2.add(frame, canvas)\n",
    "\n",
    "    stacked = np.hstack((canvas, frame))\n",
    "    cv2.imshow('Screen_Pen', cv2.resize(stacked, None, fx=0.6, fy=0.6))\n",
    "\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "    # Clear the canvas when 'c' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        canvas = None\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836f8f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit # the predicted digit is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
